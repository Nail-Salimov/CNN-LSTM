# Модель на основе CNN-LSTM для прогнозирования цен на акции
Данные о ценах на акции имеют характеристики временных рядов. В то же время, на основе долгой краткосрочной памяти машинного обучения (LSTM), которая имеет преимущества анализа взаимосвязей между данными временных рядов с помощью функции памяти, встатье предлагается метод прогнозирования курса акций на основе CNN-LSTM. Результат  гибрида сравнивался с результатами MLP, CNN, RNN, LSTM, CNN-RNN и другие модели прогнозирования.

Данные, использованные в этом исследовании, касаются дневных цен на акции с 1 июля 1991 г. по 31 августа 2020 г., включая 7127 торговых дней. Выбираны восемь характеристик, включая цену открытия, максимальную цену, минимальную цену, цену закрытия, объем, оборот, взлеты и падения и изменения.  CNN применяется для эффективного извлечения характеристик из данных, которые являются элементами за предыдущие 10 дней. А затем мы применяется LSTM для прогнозирования курса акций на основе извлеченных данных характеристик. Согласно результатам экспериментов, CNN-LSTM может обеспечить надежное прогнозирование курса акций с высочайшей точностью прогноза. Этот метод прогнозирования не только дает новую исследовательскую идею для прогнозирования цен на акции, но и дает ученым практический опыт изучения данных финансовых временных рядов.

##### **Модель CNN-LSTM**

CNN имеет свойство обращать внимание на наиболее очевидные особенности в прямой видимости, поэтому он широко используется в проектировании признаков. LSTM имеет свойство расширяться в соответствии с последовательностью времени и широко используется во временных рядах. В соответствии с характеристиками CNN и LSTM устанавливается модель прогнозирования запасов на основе CNN-LSTM. Схема структуры модели показана на рисунке, а основная структура - это CNN и LSTM, включая входной уровень, одномерный слой свертки, уровень объединения, скрытый слой LSTM и уровень полного соединения.




![alt text](https://static-01.hindawi.com/articles/complexity/volume-2020/6622927/figures/6622927.fig.001.svgz)







##### **CNN**












CNN - сетевая модель, предложенная Lecun et al. в 1998 г. CNN - это своего рода нейронная сеть с прямой связью, которая обладает хорошей производительностью при обработке изображений и обработке естественного языка. Его можно эффективно применять для прогнозирования временных рядов. Локальное восприятие и распределение веса CNN может значительно уменьшить количество параметров, тем самым повышая эффективность обучения модели. CNN в основном состоит из двух частей: сверточного слоя и объединяющего слоя. Каждый слой свертки содержит множество ядер свертки, и его формула расчета показана в формуле. После операции свертки сверточного слоя признаки данных извлекаются, но размеры извлеченных признаков очень высоки, поэтому для решения этой проблемы и снижения затрат на обучение сети после свертки добавляется слой объединения. слой, чтобы уменьшить размер объекта:


<span class="list-content">The output value of the last moment and the input value of the current time are input into the forget gate, and the output value of the forget gate is obtained after calculation, as shown in the following formula:<span class="equation_break" id="EEq2"><span class="left_break" id="L6"></span><span class="middle_break"><span class="center_break" id="M6"><svg height="18.3157pt" id="M6-1" version="1.1" viewBox="0 0 148.474 18.3157" width="148.474pt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="B6-1"><g transform="matrix(.013,0,0,-0.013,0,12.485)"><path d="M619 670C619 686 593 712 555 712S459 686 410 634S335 504 320 430H250L219 400L222 388H312L258 73C223 -133 201 -166 187 -180C175 -191 158 -199 140 -199C123 -199 88 -188 74 -172C68 -166 63 -164 54 -171C38 -185 23 -201 23 -215C23 -236 60 -261 93 -261C122 -261 161 -247 207 -200C268 -138 300 -71 337 94C365 220 376 277 394 387L501 399L521 430H401C432 623 464 665 501 665C524 665 544 651 567 627C577 617 583 618 592 625C601 631 619 651 619 670Z" id="g113-103"></path></g><g transform="matrix(.0091,0,0,-0.0091,6.72,15.617)"><use xlink:href="#g50-117"></use></g><g transform="matrix(.013,0,0,-0.013,14.02,12.485)"><use xlink:href="#g117-34"></use></g><g transform="matrix(.013,0,0,-0.013,25.28,12.485)"><path d="M548 455L523 469C505 448 490 439 461 439C416 439 374 447 316 447C144 447 23 310 23 161C23 47 89 -12 179 -12C312 -12 429 106 429 244C429 303 419 344 368 386L371 388C404 383 440 378 474 378C507 378 530 411 548 455ZM350 274C350 191 308 25 198 25C144 25 108 75 108 157C108 264 170 395 276 395C296 395 320 384 333 360C347 334 350 316 350 274Z" id="g113-240"></path></g><g transform="matrix(.013,0,0,-0.013,34.8,12.485)"><path d="M378 -385C239 -253 158 0 158 271S238 795 378 927L356 953C165 798 79 550 79 272V271C79 -10 165 -259 356 -411L378 -385Z" id="g119-133"></path></g><g transform="matrix(.013,0,0,-0.013,40.59,12.485)"><path d="M962 650H739L732 622L760 619C812 613 819 604 798 552C760 457 671 267 606 131H604L511 638H480L237 131H233L183 554C177 607 183 614 226 619L248 622L257 650H24L17 622C88 615 92 611 103 524L173 -11H203L450 491H453L543 -11H575L839 529C882 609 886 613 953 622L962 650Z" id="g113-88"></path></g><g transform="matrix(.0091,0,0,-0.0091,51.36,15.617)"><path d="M620 667C620 684 593 710 552 710C515 710 459 687 409 634C360 582 334 506 320 433H247L215 400L220 388H310L259 80C224 -129 199 -161 185 -174C175 -183 160 -192 141 -192C123 -192 90 -181 75 -165C69 -158 64 -156 54 -164C39 -178 24 -195 24 -208C24 -231 61 -257 94 -257C124 -257 162 -243 209 -194C267 -134 303 -66 343 107C369 220 378 279 393 385L503 397L523 433H404C432 619 464 660 500 660C522 660 542 646 566 621C573 614 583 615 593 621C603 628 620 648 620 667Z" id="g50-103"></path></g><g transform="matrix(.013,0,0,-0.013,60.65,12.485)"><path d="M170 255C170 288 146 313 114 313S58 288 58 255C58 221 82 198 114 198S170 221 170 255Z" id="g113-46"></path></g><g transform="matrix(.013,0,0,-0.013,66.52,12.485)"><path d="M308 -259V-228H299C192 -219 190 -215 190 -109V616C190 755 193 759 299 768H308V799H127V-259H308Z" id="g119-1"></path></g><g transform="matrix(.013,0,0,-0.013,71.37,12.485)"><path d="M499 88L487 113C459 86 422 65 413 65C403 65 403 74 409 98L461 318C487 426 460 448 431 448C408 448 383 441 352 424C305 398 223 344 157 257H155L243 674C249 702 249 712 240 712C227 712 170 680 87 673L82 648H117C155 648 162 644 150 590L23 -4L30 -12C55 -4 81 3 105 8C113 53 131 150 143 187C199 281 323 387 372 387C390 387 393 369 380 311L328 86C313 19 319 -12 347 -12C379 -12 442 24 499 88Z" id="g113-105"></path></g><g transform="matrix(.0091,0,0,-0.0091,78.01,15.617)"><use xlink:href="#g50-117"></use></g><g transform="matrix(.0091,0,0,-0.0091,81.17,15.617)"><path d="M556 236V289H56V236H556Z" id="g54-33"></path></g><g transform="matrix(.0091,0,0,-0.0091,86.73,15.617)"><path d="M389 0V32C297 38 291 46 291 118V635C234 613 175 595 109 583V556L161 554C203 552 207 547 207 497V118C207 46 201 38 110 32V0H389Z" id="g50-50"></path></g><g transform="matrix(.013,0,0,-0.013,91.71,12.485)"><use xlink:href="#g113-45"></use></g><g transform="matrix(.013,0,0,-0.013,96.85,12.485)"><use xlink:href="#g113-121"></use></g><g transform="matrix(.0091,0,0,-0.0091,104.06,15.617)"><use xlink:href="#g50-117"></use></g><g transform="matrix(.013,0,0,-0.013,107.72,12.485)"><path d="M244 -259V799H63V768H72C178 759 181 755 181 616V-109C181 -215 179 -219 72 -228H63V-259H244Z" id="g119-2"></path></g><g transform="matrix(.013,0,0,-0.013,115.55,12.485)"><use xlink:href="#g117-36"></use></g><g transform="matrix(.013,0,0,-0.013,126.08,12.485)"><use xlink:href="#g113-99"></use></g><g transform="matrix(.0091,0,0,-0.0091,131.08,15.617)"><use xlink:href="#g50-103"></use></g><g transform="matrix(.013,0,0,-0.013,137.46,12.485)"><path d="M364 271V272C364 550 278 798 87 953L65 927C205 795 285 542 285 271S204 -253 65 -385L87 -411C278 -259 364 -10 364 271Z" id="g119-134"></path></g><g transform="matrix(.013,0,0,-0.013,145.51,12.485)"><use xlink:href="#g113-45"></use></g></g></svg><svg class="alt_equation" height="18.3157pt" id="I6" version="1.1" viewBox="0 0 148.48 18.3157" width="148.48pt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><use transform="matrix(1 0 0 1 0 0)" xlink:href="#B6-1"></use></svg></span></span><span class="right_break" id="R6"><svg class="label" height="11.44pt" id="M6-2" version="1.1" viewBox="0 0 15.038 11.44" width="15.038pt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="B6-2"><g transform="matrix(.013,0,0,-0.013,0,9.25)"><use xlink:href="#g190-41"></use></g><g transform="matrix(.013,0,0,-0.013,4.5,9.25)"><path d="M411 139C381 76 368 73 314 73H129L267 224C351 317 400 380 400 469C400 574 322 635 233 635C176 635 128 610 98 576L40 495L63 476C89 515 130 568 198 568C274 568 316 519 316 436C316 347 251 264 191 192C142 134 85 76 30 21V0H403C415 45 425 89 438 131L411 139Z" id="g190-243"></path></g><g transform="matrix(.013,0,0,-0.013,10.54,9.25)"><use xlink:href="#g190-42"></use></g></g></svg><svg class="alt_label" height="18.3157pt" id="IL6" version="1.1" viewBox="0 0 15.1 18.3157" width="15.1pt" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><use transform="matrix(1 0 0 1 0 3.23)" xlink:href="#B6-2"></use></svg></span></span></span>


где представляет выходное значение после свертки, tanh - функция активации, x - входной вектор, k - вес ядра свертки и b - смещение ядра свертки.

##### **LSTM**

LSTM - это сетевая модель, предложенная Шмидхубером и др. в 1997 г. LSTM - это сетевая модель, разработанная для решения давних проблем градиентного взрыва и исчезновения градиента в RNN. Он широко используется в распознавании речи, эмоциональном анализе и анализе текста, поскольку имеет собственную память и может делать относительно точные прогнозы. В последние годы он стал применяться и в области прогнозирования фондового рынка. В стандартной RNN есть только один повторяющийся модуль, и его внутренняя структура проста. Обычно это загар. Однако четыре модуля LSTM аналогичны стандартным модулям RNN и работают особым интерактивным образом. Ячейка памяти LSTM состоит из трех частей: затвора забывания, входного затвора и выходного затвора, как показано на рисунке.


























Процесс расчета LSTM выглядит следующим образом:


1) Выходное значение последнего момента и входное значение текущего времени вводятся в ворота забывания, а выходное значение ворот забывания получается после расчета, как показано в следующей формуле:


где диапазон значений равен f (0,1), W- вес элемента забывания, b- смещение элемента забывания, x- входное значение текущего времени и h- выходное значение последнего момента.


2) Выходное значение последнего времени и входное значение текущего времени вводятся во входной вентиль, а выходное значение и состояние ячейки-кандидата входного вентиля получают после расчета, как показано в следующих формулах:






где диапазон значений i равен (0,1), Wi - вес входного элемента, b\_i- смещение входного элемента, Wc- вес входного элемента-кандидата, и b\_c - смещение входного элемента-кандидата


3) Обновите текущее состояние ячейки следующим образом:




где диапазон значений C\_t равен

4) Выход h и вход x принимаются как входные значения выходного элемента в момент времени t , а выходной o сигнал выходного элемента получается следующим образом






где диапазон значений o равен (0,1), W- вес выходного элемента, а b- смещение выходного элемента.

5) Выходное значение LSTM получается путем вычисления выходного сигнала выходного вентиля и состояния ячейки, как показано в следующей формуле




##### **Процесс обучения и прогнозирования CNN-LSTM**








































Основные шаги следующие:

1) Входные данные: введите данные, необходимые для обучения CNN-LSTM.

2) Стандартизация данных: поскольку во входных данных имеется большой пробел, для лучшего обучения модели принят метод стандартизации *z-*оценки для стандартизации входных данных, как показано в следующей формуле:




где y\_i - стандартизованное значение, x\_i- входные данные, x̅- это среднее значение входных данных, а *s*- стандартное отклонение входных данных.

3) Инициализировать сеть: инициализировать веса и смещения каждого уровня CNN-LSTM.

4) Расчет слоя CNN: входные данные последовательно проходят через сверточный слой и слой объединения в слое CNN, выполняется извлечение признаков входных данных и получается выходное значение.

5) Расчет уровня LSTM: выходные данные уровня CNN вычисляются через слой LSTM, и получается выходное значение.

6) Расчет выходного слоя: выходное значение уровня LSTM вводится в полный уровень соединения для получения выходного значения.

7) Ошибка вычисления: выходное значение, вычисленное выходным слоем, сравнивается с реальным значением этой группы данных, и получается соответствующая ошибка.

8) Чтобы определить, удовлетворяется ли условие завершения: условия завершения - выполнение заранее определенного количества циклов, вес ниже определенного порога, а частота ошибок прогнозирования ниже определенного порога. Если одно из условий завершения выполнено, обучение будет завершено, обновится вся сеть CNN-LSTM и перейдем к шагу 10; в противном случае перейдите к шагу 9.

9) Обратное распространение ошибки: распространите вычисленную ошибку в противоположном направлении, обновите вес и смещение каждого слоя и перейдите к шагу 4, чтобы продолжить обучение сети.

10) Сохранить модель: сохранить обученную модель для прогнозирования.

11) Входные данные: введите входные данные, необходимые для прогнозирования.

12) Стандартизация данных: входные данные стандартизированы по формуле (8).

13) Прогнозирование: введите стандартизированные данные в обученную модель CNN-LSTM, а затем получите соответствующее выходное значение.

14) Стандартизированное восстановление данных: выходное значение, полученное с помощью модели CNN-LSTM, является стандартизированным значением, а стандартизованное значение восстанавливается до исходного значения. Как показано в следующей формуле (9).

15) Результат вывода: вывод восстановленных результатов для завершения процесса прогнозирования.


##### **Данные**

В этом эксперименте в качестве экспериментальных данных выбран Shanghai Composite Index (000001). Ежедневные торговые данные за 7127 торговых дней с 1 июля 1991 г. по 31 августа 2020 г. получены из базы данных wind. Каждый фрагмент данных содержит восемь элементов, а именно цену открытия, максимальную цену, минимальную цену, цену закрытия, объем, оборот, взлеты и падения и изменения. Некоторые данные представлены в таблице.



##### **Реализация модели**

Чтобы оценить эффект прогнозирования CNN-LSTM, в качестве критериев оценки методов используются средняя абсолютная ошибка (MAE), среднеквадратичная ошибка (RMSE) и *R-*квадрат.

#### **Результаты**

После использования обработанных данных обучающего набора для обучения MLP, CNN, RNN, LSTM CNN-RNN и CNN-LSTM, соответственно, модель, завершенная обучением, используется для прогнозирования данных тестового набора, а реальное значение сравнивается с прогнозируемым. значение , как показано на рисунках































Результаты показывают, что производительность CNN-LSTM является лучшей среди шести методов. Что касается точности прогнозирования, MAE составляет 27,564, а RMSE - 39,688, что является наименьшим среди шести моделей прогнозирования и имеет высокую точность прогнозирования с точки зрения эффективности прогнозирования, а *R^*2  CNN-LSTM составляет 0,9646, что улучшено на 2,2%, 0,6%, 0,5% и 0,2% соответственно по сравнению с четырьмя другими методами. Следовательно, CNN-LSTM, предложенная в этой статье, превосходит другие четыре сравнительные модели с точки зрения степени соответствия и значения ошибки. Он может хорошо предсказывать цену закрытия следующего дня и служить ориентиром для инвестиций инвесторов.

#### **Выводы**
Согласно хронологическим характеристикам данных о ценах на акции, в этой статье предлагается CNN-LSTM для прогнозирования цены закрытия акций на следующий день. В этом методе в качестве входных данных используются цена открытия, максимальная цена, минимальная цена, цена закрытия, объем, оборот, взлеты и падения, а также изменение данных о запасах, полностью используя характеристики временной последовательности данных о запасах. CNN используется для извлечения характеристик входных данных. LSTM используется для изучения извлеченных данных характеристик и прогнозирования цены закрытия акции на следующий день. В этой статье в качестве примера для проверки экспериментальных результатов используются соответствующие данные Shanghai Composite Index. Результаты экспериментов показывают, что CNN-LSTM имеет самую высокую точность прогнозирования и лучшую производительность по сравнению с MLP, CNN, RNN, LSTM и CNN-RNN. MAE и RMSE - самые маленькие из всех методов,*R^*2 близок к 1. CNN-LSTM подходит для прогнозирования цен на акции и может служить релевантным ориентиром для инвесторов, чтобы максимизировать отдачу от инвестиций. CNN-LSTM также предлагает практический опыт исследования данных финансовых временных рядов. Однако у модели все же есть недостатки. Например, он учитывает только влияние данных о ценах акций на цены закрытия и не учитывает эмоциональные факторы, такие как новости и национальная политика, в прогнозе. Наша будущая исследовательская работа в основном направлена на усиление анализа настроений в отношении новостей, связанных с акциями, и национальной политики, чтобы обеспечить точность прогнозов по запасам.
